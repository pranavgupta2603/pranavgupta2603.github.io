<html>
  <head>
    <title>Pranav Gupta</title>
    <script src='js/jquery-1.11.2.min.js'></script>
    <script src='js/bootstrap.min.js'></script>
    
    <link href='css/bootstrap.min.css' rel='stylesheet'>
    <link href='http://fonts.googleapis.com/css?family=Roboto:400,500,700,900,100italic,100,300,300italic,400italic,500italic,900italic,700italic' rel='stylesheet' type='text/css'>
    <style>
      body {
        font-family: 'sans-serif';
        font-size: 12pt;
        background-color: #FFFCF4;
        color: #4F6071;
      }
      .color1 {
        background-color: #CCC;
      }
      #header {
        width: 100%;
        height: 360px;
        background-color: #F0EAD6
      }
      #header-inner {
        position: absolute;
        width: 70%;
        left: 30%;
        top: 150px;
      }
      .img-me {
        border: 3px solid white;
        float: left;
        height: 200px;
      }
      .header-text {
        margin-top: 60px;
        margin-left: 220px;
      }
      .header-text-name {
        font-weight: bold;
        font-size: 40px;
      }
      .header-text-email {
        font-size: 20px;
        font-style: italic;
      }
      .header-text-desc {
        font-size: 20px;
      }
      #contact-info {
        position: absolute;
        left: 80%;
        width: 20%;
        top: 360px;
        height: 100px;
        background-color: #EEE;
      }
      .vspace {
        margin-bottom: 20px;
      }
      .vspace-top {
        margin-top: 30px;
      }
      .paper-image {
        width: 150px;
      }
      .paper-title {
        font-size: 14pt;
        font-weight: bold;
      }
      .paper-authors {
      }
      .paper-authors a {
        color: #4F6071;
      }
      .paper-link {
      }
    </style>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-50623594-1', 'auto');
      ga('send', 'pageview');
    </script>
  </head>
  <body>
    <div id='header'>
      <div id='header-inner'>
        <img src='new_images/pfp.jpg' class='img-circle img-me'>
        <div class='header-text'>
          <div class='header-text-name'>
            Pranav Gupta
          </div>
          <div class='header-text-email'>
            pranavgupta2603 at gmail dot com
          </div>
          <div>
            <a href="https://github.com/pranavgupta2603", target="_blank">[GitHub]</a>
            <a href="https://scholar.google.com/citations?user=Lh0Gol0AAAAJ&hl=en", target="_blank">[Google Scholar]</a>
            <a href="https://x.com/pranavgupta2603", target="_blank">[Twitter]</a>
            <a href="https://www.linkedin.com/in/pranavgupta2003/", target="_blank">[LinkedIn]</a>
            <a href="https://www.medium.com/@pranavgupta2603", target="_blank">[Medium]</a>
            <a href="./Pranav Gupta CV.pdf", target="_blank">[CV]</a>

          </div>
        </div>
      </div>
    </div>

    <div class='container'>
      <div class='col-xs-10 col-md-offset-1'>
        <div class='row'>
          <h1>About</h1>
          <div class='vspace'>
            I am a Master's student in CS at the University of Michigan, Ann Arbor.
          </div>
          <div class='vspace'>
            My research interests revolve around Multimodal AI, 3D Vision, and world models.
          </div>
          <div class='vspace'>
            I worked as a <b>Research Intern</b> at Stanford's <a href="https://williamspanlab.com/", target="_blank">Personalized and Translational Neuroscience Lab (PanLab)</a> on multimodal AI in neuroimaging.
            I also interned at <a href="https://dream-lab.in/">DREAM:Lab, IISc</a> Bangalore, researching on topics related to deep learning in edge accelerators.
          </div>
          <div class='vspace'>
            I have previously interned at <a href="https://research.samsung.com/sri-b"><Samsung/a>, <a href="https://gokiwi.in/">Kiwi</a>, <a href="https://www.upthrust.io/">Upthrust</a> and <a href="https://aarogya.ai/">AarogyaAI</a> on research, multi-agentic softwares and data science projects.
          </div>
        </div>

        <div class='row'>
          <h1>Publications</h1>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='new_images/teaser_image.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                ViDAS: Vision-based Danger Assessment and Scoring
              </div>
              <div class='paper-authors'>
                <u>Pranav Gupta</u>, Advith Krishnan, Naman Nanda, Ananth Eswar, Deeksha Agarwal, Pratham Gohil, Pratyush Goel
              </div>
              <div>ICVGIP 2024</div>
              <div>
                <a href='https://dl.acm.org/doi/10.1145/3702250.3702279', target="_blank">[ACM DL]</a>
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='new_images/samsung.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                ECHO: Environmental Sound Classification With Hierarchical Ontology-Guided Semi-Supervised Learning
              </div>
              <div class='paper-authors'>
                <u>Pranav Gupta</u>, Raunak Sharma, Rashmi Kumari, Sri Krishna Aditya, Shwetank Choudhary, Sumit Kumar, Kanchana M, R Thilagavathy
              </div>
              <div>IEEE CONECCT 2024</div>
              <div>
                <a href='https://ieeexplore.ieee.org/document/10677303', target="_blank">[IEEE Xplore]</a>
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='new_images/isaap.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                ISAApp â€“ Image Based Smart Attendance Application
              </div>
              <div class='paper-authors'>
                Aritra Dutta, G Suseela, G Niranjana, Pushpita Boral, <u>Pranav Gupta</u>, Subha Bal Pal
              </div>
              <div>AAIMB 2023</div>
              <div>
                <a href='https://link.springer.com/chapter/10.1007/978-3-031-73065-8_5', target="_blank">[Springer Link]</a>
                <a href='', target="_blank">[code]</a>
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='new_images/managingcongregations.png'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                Managing Congregations of People by Predicting Likelihood of a Person being Infected by a Contagious Disease like the COVID Virus
              </div>
              <div class='paper-authors'>
                <u>Pranav Gupta</u>,
                Manish Gupta
              </div>
              <div>IEEE CCEM 2020</div>
              <div>
                <a href='https://ieeexplore.ieee.org/document/9499968', target="_blank">[IEEE Xplore]</a>
                <a href='https://github.com/pranavgupta2603/covid-spread-simulation', target="_blank">[code]</a>
              </div>
            </div>
          </div>

        </div>

        <div class='row'>
          <h1>Organizations</h1>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='new_images/ol.jpeg'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                Odyssey Lab
              </div>
              <div class='paper-authors'>
                <i>Co-Founder</i>
              </div>
              <div>Conducting research with 15 students and mentors in India from IISc, IIT, IBM, IIIT-Hyderabad</div>
              <div>
                <a href='', target="_blank">[Website Link]</a>
              </div>
            </div>
          </div>

          <div class='row vspace-top'>
            <div class='col-xs-3 text-center'>
              <img class='paper-image' src='new_images/ntl.webp'>
            </div>
            <div class='col-xs-9'>
              <div class='paper-title'>
                Next Tech Lab
              </div>
              <div class='paper-authors'>
                <i>Syndicate - Head AI Researcher</i>
              </div>
              <div>Guiding a large team of researchers, overseeing a diverse portfolio of over 40 projects in machine learning and other areas, and successfully organizing and facilitating more than 20 events and workshops for groups exceeding 50 students, have been key accomplishments.</div>
              <div>
                <a href='https://nexttechlab.in/lab/mccarthy', target="_blank">[Website Link]</a>
              </div>
            </div>
          </div>

        </div>
        
        <div class='row vspace-top'>
          <h1>Paper Implementations</h1>
          <a href='https://github.com/pranavgupta2603/CLIP-ViL-GradCAM' target='_blank'>
            <h2>CLIP-ViL-GradCam</h2>
          </a>
          A PyTorch implementation of CLIP-ViL from the paper
          <a href="https://arxiv.org/abs/2107.06383">"How Much Can CLIP Benefit Vision-and-Language Tasks?"</a> from the authors
          Sheng Shen, Liunian Harold Li, Hao Tan, Mohit Bansal, Anna Rohrbach, Kai-Wei Chang, Zhewei Yao, Kurt Keutzer

          <a href='https://github.com/pranavgupta2603/SimCLR-UrbanSound8K' target='_blank'>
            <h2>SimCLR-UrbanSound8K</h2>
          </a>
          A PyTorch implementation of SimCLR from the paper
          <a href="https://arxiv.org/abs/2002.05709">"A Simple Framework for Contrastive Learning of Visual Representations"</a> from the authors Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton on the UrbanSound8K dataset.
          Trained only on the first fold, due to inadequate computation power and produced an accuracy of 81% on melspectrogram images.

          <a href='https://github.com/pranavgupta2603/CLIP-Implementation' target='_blank'>
            <h2>CLIP</h2>
          </a>
          A PyTorch implementation of CLIP from the paper
          <a href="https://arxiv.org/abs/2103.00020">"Learning Transferable Visual Models From Natural Language Supervision"</a> from the authors Alec Radford et al. Implemented the main architecture of the model and trying to extend this architecture for VQA tasks.
          
          <a href='https://github.com/pranavgupta2603/musiclm-training' target='_blank'>
            <h2>MusicLM/AudioLDM</h2>
          </a>
          A PyTorch implementation of MusicLM and AudioLDM from the paper
          <a href="https://arxiv.org/abs/2301.12503">"AudioLDM: Text-to-Audio Generation with Latent Diffusion Models"</a> from the authors Liu et al on the MusicCaps dataset.
          Faced some errors to train the MusicLM model and currently trying to resolve them. Trained the AudioLDM model by finetuning it from the huggingface library on the melspectrogram images of the MusicCaps dataset.

          <a href='https://github.com/pranavgupta2603/ship-classification' target='_blank'>
            <h2>Siamese Network with Triplet Loss</h2>
          </a>
          A Tensorflow implementation of Siamese Network architecture with Triplet Loss from the paper
          <a href="https://arxiv.org/abs/1503.03832">"FaceNet: A Unified Embedding for Face Recognition and Clustering"</a> from the authors
          Florian Schroff, Dmitry Kalenichenko, James Philbin.
          Trained the model on the Ship Classification dataset which I scraped from <a href="https://www.shipspotting.com">Ship Spotting</a> to make an <a href="https://www.kaggle.com/datasets/pranked03/indian-ships-dataset"> Indian Ships Dataset</a> uploaded on Kaggle.
        
          <a href='https://github.com/pranavgupta2603/AI-algorithm-implementations' target='_blank'>
            <h2>AI Algorithms</h2>
          </a>
          Implementations of some basic AI algorithms like Gradient Descent and K-means with real-time visualization from scratch using NumPy and Matplotlib.
        </div>

        <div class='row vspace-top'>
          <h1>Side Projects</h1>
          <a href='https://github.com/pranavgupta2603/AI_Worldle_Solver' target='_blank'>
            <h2>AI Wordle Solver</h2>
          </a>
          Predict the next best word to play on Wordle by giving a screenshot of a partially-filled Wordle.
          <div>
            <a href='https://pranavgupta2609.medium.com/automating-game-wordle-using-computer-vision-a84010de92b7', target="_blank">[Medium Article]</a>
          </div>

          <a href='https://github.com/pranavgupta2603/SearchBrowserHistoryGPT' target='_blank'>
            <h2>Search Browser History GPT</h2>
          </a>
          Query the content of your search browser history to navigate to the desired webpage.

          <a href='https://github.com/pranavgupta2603/SplitwiseGPTVision' target='_blank'>
            <h2>Splitwise GPT Vision</h2>
          </a>
          Give an image of a bill and automatically add SplitWise entries directly into the app.

          <a href='https://github.com/pranavgupta2603/genetic-handwritten-digits' target='_blank'>
            <h2>Genetic Handwritten Digits</h2>
          </a>
          Use genetic algorithms to evolve the CNN architecture, convolution kernels size and pooling to classify handwritten digits.
          <div>
            <a href='https://medium.com/python-in-plain-english/evolving-perfection-how-genetic-algorithms-boost-handwritten-digits-models-44efbdcc5acf', target="_blank">[Medium Article]</a>
          </div>

          <a href='https://github.com/pranavgupta2603/Face-Recognition' target='_blank'>
            <h2>Face Recognition LFW</h2>
          </a>
          Used FaceNet embeddings to train SVMs using one-vs-all and one-vs-one approach to classify the LFW dataset over 86 faces.
          <div>
            <a href='https://medium.com/python-in-plain-english/how-to-create-a-face-recognition-model-using-face-embeddings-and-scikit-learns-support-vector-8c105dc1603', target="_blank">[Medium Article]</a>
          </div>
        <div class='row vspace-top'></div>

      </div>
    </div>
  </body>
</html>
